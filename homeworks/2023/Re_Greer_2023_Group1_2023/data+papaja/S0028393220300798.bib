
@article{bainbridge_resiliency_2020,
	title = {The resiliency of image memorability: {A} predictor of memory separate from attention and priming},
	volume = {141},
	issn = {0028-3932},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393220300798},
	doi = {10.1016/j.neuropsychologia.2020.107408},
	abstract = {Recent work has demonstrated there is a power within images to impact our later memories—an intrinsic stimulus memorability that influences memory behavior consistently across observers. This memorability is computed as explicitly reported memory performance on each image, and is significantly correlated from observer to observer. Interestingly, neuroimaging work has found that memorable versus forgettable images show distinct, early patterns within the brain even when participants are not performing an explicit memory task. Thus, a key question is whether memorability effects reflect a more automatic, bottom-up process, or are the result of top-down attentional processes. Further, how do bottom-up and top-down processes interact with stimulus memorability to influence ultimate memory performance? The current study explores these questions through the lens of four classical psychological phenomena shown to influence memory. First, a directed forgetting task shows that cognitive control is unable to override the effects of stimulus memorability. Second, an experiment manipulating depth of processing reveals a performance boost for memorable images regardless of the depth at which they are encoded. Third, results from a visual search experiment show that memorable images do not trigger automatic attentional capture, or pop-out. Finally, results from a repetition priming task demonstrate that memorability and priming are independent phenomena. In sum, memorability is an isolable phenomenon, occurring automatically, and resilient to top-down influence.},
	journal = {Neuropsychologia},
	author = {Bainbridge, Wilma A.},
	month = apr,
	year = {2020},
	keywords = {Bottom-up Attention, Directed forgetting, Encoding depth, Memorability, Priming, Top-down Attention, Visual search},
	pages = {107408},
}

@article{saito_judgments_2023,
	title = {Judgments of learning reveal conscious access to stimulus memorability},
	volume = {30},
	issn = {1069-9384},
	doi = {10.3758/s13423-022-02166-1},
	number = {1},
	urldate = {2022-08-30},
	journal = {PSYCHONOMIC BULLETIN \& REVIEW},
	author = {Saito, Joseph M. and Kolisnyk, Matthew and Fukuda, Keisuke},
	month = feb,
	year = {2023},
	pages = {317--330},
}

@article{bainbridge_intrinsic_2013,
	title = {The {Intrinsic} {Memorability} of {Face} {Photographs}},
	volume = {142},
	issn = {0096-3445},
	doi = {10.1037/a0033872},
	number = {4},
	urldate = {2013-12-11},
	journal = {JOURNAL OF EXPERIMENTAL PSYCHOLOGY-GENERAL},
	author = {Bainbridge, Wilma A. and Isola, Phillip and Oliva, Aude},
	month = nov,
	year = {2013},
	pages = {1323--1334},
}

@article{forsberg_childrens_2022,
	title = {Children's long-term retention is directly constrained by their working memory capacity limitations},
	volume = {25},
	copyright = {© 2021 John Wiley \& Sons Ltd.},
	issn = {1467-7687},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.13164},
	doi = {10.1111/desc.13164},
	abstract = {We explored the causal role of individual and age-related differences in working memory (WM) capacity in long-term memory (LTM) retrieval. Our sample of 160 participants included 120 children (6–13-years old) and 40 young adults (18–24 years). Participants performed a WM task with images of unique everyday items, presented at varying set sizes. Subsequently, we tested participants' LTM for items from the WM task. Using these measures, we estimated the ratio at which items successfully held in WM were recognized in LTM. While WM and LTM generally improved with age, the ability to transfer information from WM to LTM appeared consistent between age groups. Moreover, individual differences in WM capacity appeared to predict LTM encoding. Overall, these results suggested that LTM performance was constrained by experimental, individual, and age-related WM limitations. We discuss the theoretical and practical implications of this WM-to-LTM bottleneck.},
	language = {en},
	number = {2},
	urldate = {2023-06-30},
	journal = {Developmental Science},
	author = {Forsberg, Alicia and Guitard, Dominic and Adams, Eryn J. and Pattanakul, Duangporn and Cowan, Nelson},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.13164},
	keywords = {child development, information transfer, long-term memory, working memory},
	pages = {e13164},
	file = {Forsberg et al_2022_Children's long-term retention is directly constrained by their working memory.pdf:D\:\\literature\\Developmental Science2022\\Forsberg et al_2022_Children's long-term retention is directly constrained by their working memory.pdf:application/pdf},
}

@article{isola_what_2014,
	title = {What {Makes} a {Photograph} {Memorable}?},
	volume = {36},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2013.200},
	abstract = {When glancing at a magazine, or browsing the Internet, we are continuously exposed to photographs. Despite this overflow of visual information, humans are extremely good at remembering thousands of pictures along with some of their visual details. But not all images are equal in memory. Some stick in our minds while others are quickly forgotten. In this paper, we focus on the problem of predicting how memorable an image will be. We show that memorability is an intrinsic and stable property of an image that is shared across different viewers, and remains stable across delays. We introduce a database for which we have measured the probability that each picture will be recognized after a single view. We analyze a collection of image features, labels, and attributes that contribute to making an image memorable, and we train a predictor based on global image descriptors. We find that predicting image memorability is a task that can be addressed with current computer vision techniques. While making memorable images is a challenging task in visualization, photography, and education, this work is a first attempt to quantify this useful property of images.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Isola, Phillip and Xiao, Jianxiong and Parikh, Devi and Torralba, Antonio and Oliva, Aude},
	month = jul,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Atmospheric measurements, attributes, Correlation, Delays, Games, global image features, image memorability, Observers, Particle measurements, Scene Analysis, Scene understanding, Vision and Scene Understanding, Visualization},
	pages = {1469--1482},
}

@book{singmann_afex_2023,
	title = {afex: {Analysis} of {Factorial} {Experiments}},
	url = {https://CRAN.R-project.org/package=afex},
	author = {Singmann, Henrik and Bolker, Ben and Westfall, Jake and Aust, Frederik and Ben-Shachar, Mattan S.},
	year = {2023},
	annote = {R package version 1.2-1},
}

@book{r_core_team_r_2023,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2023},
}

@book{wickham_dplyr_2023,
	title = {dplyr: {A} {Grammar} of {Data} {Manipulation}},
	url = {https://CRAN.R-project.org/package=dplyr},
	author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and Vaughan, Davis},
	year = {2023},
	annote = {R package version 1.1.0},
}

@book{lenth_emmeans_2023,
	title = {emmeans: {Estimated} {Marginal} {Means}, aka {Least}-{Squares} {Means}},
	url = {https://CRAN.R-project.org/package=emmeans},
	author = {Lenth, Russell V.},
	year = {2023},
	annote = {R package version 1.8.5},
}

@book{wickham_ggplot2_2016,
	title = {ggplot2: {Elegant} {Graphics} for {Data} {Analysis}},
	isbn = {978-3-319-24277-4},
	url = {https://ggplot2.tidyverse.org},
	publisher = {Springer-Verlag New York},
	author = {Wickham, Hadley},
	year = {2016},
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} lme4},
	volume = {67},
	doi = {10.18637/jss.v067.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	pages = {1--48},
}

@book{bates_matrix_2022,
	title = {Matrix: {Sparse} and {Dense} {Matrix} {Classes} and {Methods}},
	url = {https://CRAN.R-project.org/package=Matrix},
	author = {Bates, Douglas and Maechler, Martin and Jagan, Mikael},
	year = {2022},
	annote = {R package version 1.5-3},
}

@book{aust_papaja_2022,
	title = {papaja: {Prepare} reproducible {APA} journal articles with {R} {Markdown}},
	url = {https://github.com/crsh/papaja},
	author = {Aust, Frederik and Barth, Marius},
	year = {2022},
	annote = {R package version 0.1.1},
}

@book{pedersen_patchwork_2022,
	title = {patchwork: {The} {Composer} of {Plots}},
	url = {https://CRAN.R-project.org/package=patchwork},
	author = {Pedersen, Thomas Lin},
	year = {2022},
	annote = {R package version 1.1.2},
}

@book{wickham_tidyr_2023,
	title = {tidyr: {Tidy} {Messy} {Data}},
	url = {https://CRAN.R-project.org/package=tidyr},
	author = {Wickham, Hadley and Vaughan, Davis and Girlich, Maximilian},
	year = {2023},
	annote = {R package version 1.3.0},
}

@book{barth_tinylabels_2022,
	title = {tinylabels: {Lightweight} {Variable} {Labels}},
	url = {https://cran.r-project.org/package=tinylabels},
	author = {Barth, Marius},
	year = {2022},
	annote = {R package version 0.2.3},
}

@article{makowski_bayestestr_2019,
	title = {{bayestestR}: {Describing} {Effects} and their {Uncertainty}, {Existence} and {Significance} within the {Bayesian} {Framework}.},
	volume = {4},
	url = {https://joss.theoj.org/papers/10.21105/joss.01541},
	doi = {10.21105/joss.01541},
	number = {40},
	journal = {Journal of Open Source Software},
	author = {Makowski, Dominique and Ben-Shachar, Mattan S. and Lüdecke, Daniel},
	year = {2019},
	pages = {1541},
}

@book{bao_brucer_2023,
	title = {{bruceR}: {Broadly} {Useful} {Convenient} and {Efficient} {R} {Functions}},
	url = {https://CRAN.R-project.org/package=bruceR},
	author = {Bao, Han-Wu-Shuang},
	year = {2023},
	annote = {R package version 0.8.10},
}

@book{dowle_datatable_2023,
	title = {data.table: {Extension} of `data.frame`},
	url = {https://CRAN.R-project.org/package=data.table},
	author = {Dowle, Matt and Srinivasan, Arun},
	year = {2023},
	annote = {R package version 1.14.8},
}

@article{ben-shachar_effectsize_2020,
	title = {effectsize: {Estimation} of {Effect} {Size} {Indices} and {Standardized} {Parameters}},
	volume = {5},
	url = {https://doi.org/10.21105/joss.02815},
	doi = {10.21105/joss.02815},
	number = {56},
	journal = {Journal of Open Source Software},
	author = {Ben-Shachar, Mattan S. and Lüdecke, Daniel and Makowski, Dominique},
	year = {2020},
	note = {Publisher: The Open Journal},
	pages = {2815},
}

@book{muller_here_2020,
	title = {here: {A} {Simpler} {Way} to {Find} {Your} {Files}},
	url = {https://CRAN.R-project.org/package=here},
	author = {Müller, Kirill},
	year = {2020},
	annote = {R package version 1.0.1},
}

@book{long_interactions_2019,
	title = {interactions: {Comprehensive}, {User}-{Friendly} {Toolkit} for {Probing} {Interactions}},
	url = {https://cran.r-project.org/package=interactions},
	author = {Long, Jacob A.},
	year = {2019},
	annote = {R package version 1.1.0},
}

@article{nordmann_data_2021,
	title = {Data visualisation using {R}, for researchers who don't use {R}},
	url = {https://psyteachr.github.io/introdataviz},
	journal = {Preprint},
	author = {{Nordmann} and {E.} and {McAleer} and {P.} and {Toivo} and {W.} and {Paterson} and DeBruine, H. \& and {L.}},
	year = {2021},
}

@article{kuznetsova_lmertest_2017,
	title = {{lmerTest} {Package}: {Tests} in {Linear} {Mixed} {Effects} {Models}},
	volume = {82},
	doi = {10.18637/jss.v082.i13},
	number = {13},
	journal = {Journal of Statistical Software},
	author = {Kuznetsova, Alexandra and Brockhoff, Per B. and Christensen, Rune H. B.},
	year = {2017},
	pages = {1--26},
}

@article{ludecke_performance_2021,
	title = {performance: {An} {R} {Package} for {Assessment}, {Comparison} and {Testing} of {Statistical} {Models}},
	volume = {6},
	doi = {10.21105/joss.03139},
	number = {60},
	journal = {Journal of Open Source Software},
	author = {Lüdecke, Daniel and Ben-Shachar, Mattan S. and Patil, Indrajeet and Waggoner, Philip and Makowski, Dominique},
	year = {2021},
	pages = {3139},
}

@book{wickham_stringr_2022,
	title = {stringr: {Simple}, {Consistent} {Wrappers} for {Common} {String} {Operations}},
	url = {https://CRAN.R-project.org/package=stringr},
	author = {Wickham, Hadley},
	year = {2022},
	annote = {R package version 1.5.0},
}

@article{R-papaja,
  author = {Frederik Aust and Marius Barth},
  title = {{papaja}: {Create} {APA} manuscripts with {R Markdown}}
}


@article{schoenbrodt_sequential_2017,
	title = {Sequential hypothesis testing with {Bayes} factors: {Efficiently} testing mean differences},
	volume = {22},
	issn = {1939-1463},
	shorttitle = {Sequential hypothesis testing with {Bayes} factors},
	doi = {10.1037/met0000061},
	abstract = {Unplanned optional stopping rules have been criticized for inflating Type I error rates under the null hypothesis significance testing (NHST) paradigm. Despite these criticisms, this research practice is not uncommon, probably because it appeals to researcher’s intuition to collect more data to push an indecisive result into a decisive region. In this contribution, we investigate the properties of a procedure for Bayesian hypothesis testing that allows optional stopping with unlimited multiple testing, even after each participant. In this procedure, which we call Sequential Bayes Factors (SBFs), Bayes factors are computed until an a priori defined level of evidence is reached. This allows flexible sampling plans and is not dependent upon correct effect size guesses in an a priori power analysis. We investigated the long-term rate of misleading evidence, the average expected sample sizes, and the biasedness of effect size estimates when an SBF design is applied to a test of mean differences between 2 groups. Compared with optimal NHST, the SBF design typically needs 50\% to 70\% smaller samples to reach a conclusion about the presence of an effect, while having the same or lower long-term rate of wrong inference. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Methods},
	author = {Schoenbrodt, Felix D. and Wagenmakers, Eric-Jan and Zehetleitner, Michael and Perugini, Marco},
	year = {2017},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Hypothesis Testing, Null Hypothesis Testing, Statistical Probability, Type I Errors, Mean},
	pages = {322--339},
}